{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 10:02:54.757752: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-27 10:02:54.760307: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-27 10:02:54.807986: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-27 10:02:54.809214: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-27 10:02:57.472674: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/sharmam8/.local/lib/python3.11/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "#from keras.api._v2.keras.metrics import F1Score\n",
    "import tensorflow_addons as tfa\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "np.set_printoptions(precision=4)\n",
    "print(tf.version.VERSION)\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "#logger = logging.getLogger(ww.__name__)\n",
    "#logger.setLevel(logging.INFO)\n",
    "checkpoint_path = \"/home/sharmam8/Tests/experiments/logs/23Jul16_combined/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "my_callbacks = [\n",
    "tf.keras.callbacks.EarlyStopping(patience=2),\n",
    "tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant ID</th>\n",
       "      <th>Trial ID</th>\n",
       "      <th>Trial Type</th>\n",
       "      <th>Pulse Width</th>\n",
       "      <th>Contraction Start Time(s)</th>\n",
       "      <th>Contraction End Time (s)</th>\n",
       "      <th>ContractionNo</th>\n",
       "      <th>Pain Label</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Previous Injury</th>\n",
       "      <th>Fibula Length</th>\n",
       "      <th>Shank Girth</th>\n",
       "      <th>Time(s)</th>\n",
       "      <th>EMG(mv)</th>\n",
       "      <th>MMG_x</th>\n",
       "      <th>MMG_y</th>\n",
       "      <th>MMG_z</th>\n",
       "      <th>ContractionDuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.677351</td>\n",
       "      <td>6.506103</td>\n",
       "      <td>9.183454</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.5062</td>\n",
       "      <td>95.524229</td>\n",
       "      <td>1.591994</td>\n",
       "      <td>1.301494</td>\n",
       "      <td>1.546334</td>\n",
       "      <td>2.677351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.677351</td>\n",
       "      <td>6.506103</td>\n",
       "      <td>9.183454</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.5064</td>\n",
       "      <td>95.876228</td>\n",
       "      <td>1.596378</td>\n",
       "      <td>1.301486</td>\n",
       "      <td>1.546180</td>\n",
       "      <td>2.677351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.677351</td>\n",
       "      <td>6.506103</td>\n",
       "      <td>9.183454</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.5066</td>\n",
       "      <td>96.267965</td>\n",
       "      <td>1.600714</td>\n",
       "      <td>1.301478</td>\n",
       "      <td>1.546035</td>\n",
       "      <td>2.677351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.677351</td>\n",
       "      <td>6.506103</td>\n",
       "      <td>9.183454</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.5068</td>\n",
       "      <td>96.670317</td>\n",
       "      <td>1.604998</td>\n",
       "      <td>1.301471</td>\n",
       "      <td>1.545901</td>\n",
       "      <td>2.677351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.677351</td>\n",
       "      <td>6.506103</td>\n",
       "      <td>9.183454</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.5070</td>\n",
       "      <td>97.063615</td>\n",
       "      <td>1.609228</td>\n",
       "      <td>1.301467</td>\n",
       "      <td>1.545781</td>\n",
       "      <td>2.677351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant ID  Trial ID  Trial Type  Pulse Width  \\\n",
       "0               1        11           1     2.677351   \n",
       "1               1        11           1     2.677351   \n",
       "2               1        11           1     2.677351   \n",
       "3               1        11           1     2.677351   \n",
       "4               1        11           1     2.677351   \n",
       "\n",
       "   Contraction Start Time(s)  Contraction End Time (s)  ContractionNo  \\\n",
       "0                   6.506103                  9.183454              1   \n",
       "1                   6.506103                  9.183454              1   \n",
       "2                   6.506103                  9.183454              1   \n",
       "3                   6.506103                  9.183454              1   \n",
       "4                   6.506103                  9.183454              1   \n",
       "\n",
       "   Pain Label  Sex  Age  ...  Weight  Previous Injury  Fibula Length  \\\n",
       "0           1    1   23  ...    50.0                0           35.0   \n",
       "1           1    1   23  ...    50.0                0           35.0   \n",
       "2           1    1   23  ...    50.0                0           35.0   \n",
       "3           1    1   23  ...    50.0                0           35.0   \n",
       "4           1    1   23  ...    50.0                0           35.0   \n",
       "\n",
       "   Shank Girth  Time(s)    EMG(mv)     MMG_x     MMG_y     MMG_z  \\\n",
       "0         35.0   6.5062  95.524229  1.591994  1.301494  1.546334   \n",
       "1         35.0   6.5064  95.876228  1.596378  1.301486  1.546180   \n",
       "2         35.0   6.5066  96.267965  1.600714  1.301478  1.546035   \n",
       "3         35.0   6.5068  96.670317  1.604998  1.301471  1.545901   \n",
       "4         35.0   6.5070  97.063615  1.609228  1.301467  1.545781   \n",
       "\n",
       "   ContractionDuration  \n",
       "0             2.677351  \n",
       "1             2.677351  \n",
       "2             2.677351  \n",
       "3             2.677351  \n",
       "4             2.677351  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "all_files =  sorted(str(p) for p in pathlib.Path('/home/sharmam8/Tests/experiments/data').glob(\"*.csv\"))\n",
    "df = pd.read_csv(\"/home/sharmam8/Tests/experiments/data/_11_MATRIX.csv\")\n",
    "for i in range(len(all_files)-1):\n",
    "  temp = pd.read_csv(all_files[i])\n",
    "  df = pd.concat([df, temp], axis=0)\n",
    "  #print(len(df.index))\n",
    "df['ContractionDuration'] = df['Contraction End Time (s)'] - df['Contraction Start Time(s)']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(my_state):\n",
    "  #select features\n",
    "  X = df[['Trial Type', 'ContractionDuration', 'Pulse Width', \\\n",
    "          'Contraction Start Time(s)', 'Contraction End Time (s)', 'ContractionNo', \\\n",
    "          'Sex', 'Age', 'Height', 'Weight', 'Previous Injury', 'Fibula Length', 'Shank Girth', \\\n",
    "          'Time(s)', 'EMG(mv)', 'MMG_x', 'MMG_y', 'MMG_z', 'ContractionDuration'\n",
    "          ]]\n",
    "  y = df['Pain Label']\n",
    "  #create data split\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=my_state)\n",
    "  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=my_state)\n",
    "  print(\"Number of samples in the training set: \", len(X_train))\n",
    "  print(\"Number of samples in the test set: \", len(X_test))\n",
    "  print(\"Number of samples in the validation set: \", len(X_val))\n",
    "  #scale the data\n",
    "  from sklearn.preprocessing import StandardScaler\n",
    "  scaler = StandardScaler()\n",
    "  X_train_scaled = scaler.fit_transform(X_train)\n",
    "  X_test_scaled = scaler.transform(X_test)\n",
    "  X_val_scaled = scaler.transform(X_val)\n",
    "  return X_train_scaled, X_test_scaled, X_val_scaled, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_FCNN_model(my_state, num_feat):\n",
    "  tf.random.set_seed(my_state)\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(1024, activation='relu', name=\"relu1Layer\"),\n",
    "      tf.keras.layers.Dense(1024, activation='relu', name=\"relu2Layer\"),\n",
    "      tf.keras.layers.Dense(1024, activation='relu', name=\"relu3Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu4Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu5Layer\"),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
    "        tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
    "    ]\n",
    "  )\n",
    "  return model\n",
    "\n",
    "def create_CNN_model(my_state, num_feat):\n",
    "  tf.random.set_seed(my_state)\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv1D(100, num_feat, activation='relu', name=\"convLayer\", input_shape=(num_feat, 1)),\n",
    "      tf.keras.layers.MaxPooling1D(pool_size=2, strides=1, padding=\"same\"),\n",
    "      #tf.keras.layers.Conv1D(100, num_feat, activation='relu', name=\"convLayer2\", input_shape=(num_feat, 1)),\n",
    "      #tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(1024, activation='relu', name=\"relu1Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu2Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu3Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu4Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu5Layer\"),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
    "        tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
    "\n",
    "    ]\n",
    "  )\n",
    "  return model\n",
    "\n",
    "def create_tuned_CNN_model(my_state, factor, rate, num_feat):\n",
    "  tf.random.set_seed(my_state)\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv1D(100, num_feat, activation='relu', name=\"convLayer\", input_shape=(num_feat, 1)),\n",
    "      tf.keras.layers.MaxPooling1D(pool_size=2, strides=1, padding=\"same\"),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(1024, kernel_regularizer=l2(factor), activation='relu', name=\"relu1Layer\"),\n",
    "      tf.keras.layers.BatchNormalization(synchronized=True),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.BatchNormalization(synchronized=True),\n",
    "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu2Layer\"),\n",
    "      tf.keras.layers.BatchNormalization(synchronized=True),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.BatchNormalization(synchronized=True),\n",
    "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu3Layer\"),\n",
    "      tf.keras.layers.BatchNormalization(synchronized=True),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.BatchNormalization(synchronized=True),\n",
    "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu4Layer\"),\n",
    "      tf.keras.layers.BatchNormalization(synchronized=True),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.BatchNormalization(synchronized=True),\n",
    "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu5Layer\"),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
    "        tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
    "\n",
    "    ]\n",
    "  )\n",
    "  return model\n",
    "\n",
    "def create_LSTM_model(my_state, num_feat):\n",
    "  tf.random.set_seed(my_state)\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.LSTM(256, input_shape=(num_feat, 1)),\n",
    "      tf.keras.layers.Dense(128, activation='relu', name=\"relu1Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu2Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu3Layer\"),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
    "  ])\n",
    "  model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
    "        tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
    "    ]\n",
    "  )\n",
    "  return model\n",
    "\n",
    "def create_regularized_LSTM_model(my_state, factor, rate, num_feat):\n",
    "  tf.random.set_seed(my_state)\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.LSTM(256, input_shape=(num_feat, 1)),\n",
    "      #Dropout(rate),\n",
    "      #tf.keras.layers.LSTM(128, input_shape=(None, 1, 256)),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Dense(128, kernel_regularizer=l2(factor), activation='relu', name=\"relu1Layer\"),\n",
    "      tf.keras.layers.BatchNormalization(synchronized=True),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu2Layer\"),\n",
    "      tf.keras.layers.BatchNormalization(synchronized=True),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu3Layer\"),\n",
    "      tf.keras.layers.BatchNormalization(synchronized=True),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu4Layer\"),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
    "      #tf.keras.layers.Dense(1, activation='relu', name=\"reluLayer\")\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.binary_crossentropy,\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "      metrics=[\n",
    "          tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "          tf.keras.metrics.Precision(name='precision'),\n",
    "          tf.keras.metrics.Recall(name='recall'),\n",
    "          tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
    "          tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
    "      ]\n",
    "  )\n",
    "  return model\n",
    "\n",
    "def create_combined_model(my_state, factor, rate, num_feat):\n",
    "  tf.random.set_seed(my_state)\n",
    "  model = tf.keras.Sequential([\n",
    "      ### BUILD FEATURE EXTRACTOR\n",
    "\n",
    "      tf.keras.layers.Conv1D(100, num_feat, activation='relu', name=\"convLayer\", input_shape=(num_feat, 1)),\n",
    "      tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "      tf.keras.layers.Conv1D(filters=32, kernel_size=3,padding='same',activation='relu'),\n",
    "      tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(1024, activation='relu', name=\"relu1Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu2Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu3Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu4Layer\"),\n",
    "      tf.keras.layers.Dense(256, activation='relu', name=\"relu5Layer\"),\n",
    "\n",
    "      ###FEED INTO LSTM\n",
    "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1024, return_sequences=True)),\n",
    "      #tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True)),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Dense(128, kernel_regularizer=l2(factor), activation='relu', name=\"relu1Layer\"),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu2Layer\"),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu3Layer\"),\n",
    "      Dropout(rate),\n",
    "      tf.keras.layers.Dense(256, kernel_regularizer=l2(factor), activation='relu', name=\"relu4Layer\"),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid', name=\"sigmoidLayer\")\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.BinaryCrossentropy(name='binary cross entropy'),\n",
    "        tf.keras.metrics.BinaryIoU(name='binary IoU')\n",
    "\n",
    "    ]\n",
    "  )\n",
    "  return model\n",
    "\n",
    "\n",
    "####################### TRAINING\n",
    "def train_model(model, X_train_scaled, y_train, num_epochs, checkpoint_dir, t_callbacks):\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=checkpoint_dir, histogram_freq=1)\n",
    "  print(\"Training the neural network.. \")\n",
    "  history = model.fit(X_train_scaled, y_train, batch_size=32, epochs=num_epochs, callbacks=t_callbacks)\n",
    "  model.summary()\n",
    "  return history\n",
    "\n",
    "######################## VISUALS\n",
    "def visualize_performance(num_epochs, history):\n",
    "  import matplotlib.pyplot as plt\n",
    "  from matplotlib import rcParams\n",
    "  rcParams['figure.figsize'] = (18, 8)\n",
    "  rcParams['axes.spines.top'] = False\n",
    "  rcParams['axes.spines.right'] = False\n",
    "  plt.plot(\n",
    "      np.arange(1, num_epochs+1),\n",
    "      history.history['loss'], label='Loss'\n",
    "  )\n",
    "  plt.plot(\n",
    "      np.arange(1, num_epochs+1),\n",
    "      history.history['accuracy'], label='Accuracy'\n",
    "  )\n",
    "  plt.plot(\n",
    "      np.arange(1, num_epochs+1),\n",
    "      history.history['precision'], label='Precision'\n",
    "  )\n",
    "  plt.plot(\n",
    "      np.arange(1, num_epochs+1),\n",
    "      history.history['recall'], label='Recall'\n",
    "  )\n",
    "  plt.title('Evaluation metrics', size=20)\n",
    "  plt.xlabel('Epoch', size=14)\n",
    "  plt.legend()\n",
    "\n",
    "\n",
    "############### PERFORMANCE\n",
    "def evaluate_performance(model, X_test_scaled, y_test):\n",
    "  predictions = model.predict(X_test_scaled)\n",
    "  prediction_classes = [\n",
    "      1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
    "  ]\n",
    "  prediction_classes = [\n",
    "      1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
    "  ]\n",
    "  from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "  print(f'Accuracy: {accuracy_score(y_test, prediction_classes):.4f}')\n",
    "  print(f'Precision: {precision_score(y_test, prediction_classes):.4f}')\n",
    "  print(f'Recall: {recall_score(y_test, prediction_classes):.4f}')\n",
    "  print(f'F1 Score: {f1_score(y_test, prediction_classes):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup for training\n",
    "checkpoint_path = \"/home/sharmam8/Tests/experiments/logs/23Jul27_tuned_LSTM_s10_repeated/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "my_callbacks = [\n",
    "#tf.keras.callbacks.EarlyStopping(patience=2),\n",
    "#tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \\\n",
    "                                                save_weights_only=True, \\\n",
    "                                                verbose=1)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "X = df[['Trial Type', 'ContractionDuration', 'Pulse Width', \\\n",
    "        'Contraction Start Time(s)', 'Contraction End Time (s)', 'ContractionNo', \\\n",
    "        'Sex', 'Age', 'Height', 'Weight', 'Previous Injury', 'Fibula Length', 'Shank Girth', \\\n",
    "        'Time(s)', 'EMG(mv)', 'MMG_x', 'MMG_y', 'MMG_z', 'ContractionDuration'\n",
    "        ]]\n",
    "y = df['Pain Label']\n",
    "groups = df['Participant ID']\n",
    "logo = LeaveOneGroupOut()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "my_state = 999\n",
    "num_epochs = 5\n",
    "num_feat = 19\n",
    "factor = 1e-5\n",
    "rate = 0.3\n",
    "#create model\n",
    "#model = create_FCNN_model(my_state, num_feat)\n",
    "#model = create_LSTM_model(my_state, num_feat)\n",
    "#model = create_CNN_model(my_state, num_feat)\n",
    "model = create_regularized_LSTM_model(my_state, factor, rate, num_feat)\n",
    "#model = create_tuned_CNN_model(my_state, factor, rate, num_feat)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "n = 10\n",
    "X_train = X[df['Participant ID'] != n]\n",
    "y_train = y[df['Participant ID'] != n]\n",
    "X_test = X[df['Participant ID'] == n]\n",
    "y_test = y[df['Participant ID'] == n]\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "history = train_model(model, X_train_scaled, y_train, num_epochs, checkpoint_dir, my_callbacks)\n",
    "evaluate_performance(model, X_test_scaled, y_test)\n",
    "\n",
    "# for n in subjects:\n",
    "# X_train = X[df['Participant ID'] != n]\n",
    "# y_train = y[df['Participant ID'] != n]\n",
    "# X_test = X[df['Participant ID'] == n]\n",
    "# y_test = y[df['Participant ID'] == n]\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "# history = train_model(model, X_train_scaled, y_train, num_epochs, checkpoint_dir, cp_callback)\n",
    "# evaluate_performance(model, X_test_scaled, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_state = 86\n",
    "num_epochs = 1\n",
    "num_feat = 19\n",
    "#create model\n",
    "X_train_scaled, X_test_scaled, X_val_scaled, y_train, y_test, y_val = data_prep(my_state)\n",
    "model = create_FCNN_model(my_state, num_feat)\n",
    "#model = create_combined_model(my_state, 1e-5, 0.3, num_feat)\n",
    "history = train_model(X_train_scaled, y_train, num_epochs)\n",
    "evaluate_performance(model, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='log.csv'\n",
    "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3 (main, Apr  5 2023, 12:28:08) [GCC 8.5.0 20210514 (Red Hat 8.5.0-10)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41fc8b36bf36cc77c8f0aca9aaae7dca48fa14cb9a0f039c96478316eae00f84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
